{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "386de643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.cwd().parent)) \n",
    "from tool_monkey import MonkeyObserver, with_monkey, single_timeout, logger, setup_default_logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb971f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "setup_default_logging(level=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2773c9d7",
   "metadata": {},
   "source": [
    "Example 1: Using `bind_tools()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c610588",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: Full LLM Response: content='' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 134, 'total_tokens': 149, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-CwsTgELuVSi3lUI8XSO1DR7G2teQJ', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='lc_run--019baddc-8f9b-7951-84f5-91fb08811a42-0' tool_calls=[{'name': 'get_weather', 'args': {'location': 'Boston'}, 'id': 'call_1uRToUYDAvOhDMrhWnqkXMlv', 'type': 'tool_call'}] invalid_tool_calls=[] usage_metadata={'input_tokens': 134, 'output_tokens': 15, 'total_tokens': 149, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "DEBUG: Have tool calls? Yes\n",
      "DEBUG: Invoking tool: get_weather with args {'location': 'Boston'}\n",
      "INFO: Simulating timeout for 3.0 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "OBSERVER METRICS:\n",
      "==================================================\n",
      "Tool Monkey Execution Summary\n",
      "  ==============================\n",
      "  Total Calls: 1\n",
      "  Success Rate: 0.0%\n",
      "  Failures: 1\n",
      "  Total Retries: 0\n",
      "  Avg Latency: 3001.5ms\n"
     ]
    }
   ],
   "source": [
    "def bind_tools_example():\n",
    "    from langchain_examples.shared.llm import llm\n",
    "    from langchain_examples.shared.tools import base_weather_tool \n",
    "    from langchain_core.tools import tool\n",
    "    observer=MonkeyObserver()\n",
    "    scenario=single_timeout(seconds=3.0)\n",
    "    wrapped_base_weather_tool=with_monkey(scenario, observer)(base_weather_tool)\n",
    "    @tool\n",
    "    def get_weather(location: str, units: str = \"celcius\"):\n",
    "        \"\"\"Get the current weather for a given location.\n",
    "            Args:\n",
    "                location (str): The location to get the weather for.\n",
    "                units (str): The units to return the weather in. Either 'celsius' or 'fahrenheit'.\n",
    "            Returns:\n",
    "                str: The current weather in the given location.\"\"\"\n",
    "        return wrapped_base_weather_tool(location, units)\n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant with access to a tool to get weather information.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather in Boston?\"}]\n",
    "    llm_with_tool = llm.bind_tools([get_weather])\n",
    "    # invoke the model with the messages\n",
    "    ai_msg = llm_with_tool.invoke(messages)\n",
    "    logger.debug(f\"Full LLM Response: {ai_msg}\")\n",
    "    messages.append(ai_msg)\n",
    "    logger.debug(f\"Have tool calls? {'Yes' if ai_msg.tool_calls else 'No'}\")\n",
    "    try:\n",
    "        for tool_call in ai_msg.tool_calls:\n",
    "            logger.debug(\n",
    "                f\"Invoking tool: {tool_call.get(\"name\")} with args {tool_call.get('args')}\")\n",
    "            tool_result = get_weather.invoke(tool_call)\n",
    "            logger.debug(f\"Tool result: {tool_result}\")\n",
    "            messages.append(tool_result)\n",
    "        final_response = llm_with_tool.invoke(messages)\n",
    "        logger.debug(f\"Final LLM Response: {final_response.text}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"OBSERVER METRICS:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(observer.summary())\n",
    "\n",
    "bind_tools_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd653e36",
   "metadata": {},
   "source": [
    "Example 2: Using `create_agent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1085f407",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Simulating timeout for 3.0 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "OBSERVER METRICS:\n",
      "==================================================\n",
      "Tool Monkey Execution Summary\n",
      "  ==============================\n",
      "  Total Calls: 1\n",
      "  Success Rate: 0.0%\n",
      "  Failures: 1\n",
      "  Total Retries: 0\n",
      "  Avg Latency: 3002.0ms\n"
     ]
    }
   ],
   "source": [
    "def create_agent_example():\n",
    "    from langchain.agents import create_agent\n",
    "    from langchain_examples.shared.llm import llm\n",
    "    from langchain_examples.shared.tools import base_weather_tool \n",
    "    from langchain_core.tools import tool\n",
    "    observer=MonkeyObserver()\n",
    "    scenario=single_timeout(seconds=3.0)\n",
    "    wrapped_base_weather_tool=with_monkey(scenario, observer)(base_weather_tool)\n",
    "    @tool\n",
    "    def get_weather(location: str, units: str = \"celcius\"):\n",
    "        \"\"\"Get the current weather for a given location.\n",
    "            Args:\n",
    "                location (str): The location to get the weather for.\n",
    "                units (str): The units to return the weather in. Either 'celsius' or 'fahrenheit'.\n",
    "            Returns:\n",
    "                str: The current weather in the given location.\"\"\"\n",
    "        return wrapped_base_weather_tool(location, units)\n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant with access to a tool to get weather information.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather in Boston?\"}]\n",
    "    agent=create_agent(model=llm, tools=[get_weather])\n",
    "    try:\n",
    "        response=agent.invoke(input={\"messages\":messages})\n",
    "        final_message=response[\"messages\"][-1]\n",
    "        print(f\"Final response: {final_message.content}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"OBSERVER METRICS:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(observer.summary())\n",
    "\n",
    "create_agent_example()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3806b97",
   "metadata": {},
   "source": [
    "Example 3: Using a retry strategy (with `tenacity`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b75e0bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: Full LLM Response: content='' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 134, 'total_tokens': 149, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-CwtfQsbgs5kgZCOW6Lge6IA2CIdO7', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='lc_run--019bae22-5207-7b21-a139-3e18278483ab-0' tool_calls=[{'name': 'get_weather', 'args': {'location': 'Boston'}, 'id': 'call_wt8NfTXmIWZYBxbiHXaMH6VZ', 'type': 'tool_call'}] invalid_tool_calls=[] usage_metadata={'input_tokens': 134, 'output_tokens': 15, 'total_tokens': 149, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "DEBUG: Have tool calls? Yes\n",
      "DEBUG: Invoking tool: get_weather with args {'location': 'Boston'}\n",
      "INFO: Simulating timeout for 3.0 seconds\n",
      "DEBUG: Tool result: content='Current weather in Boston: 72 degrees C' name='get_weather' tool_call_id='call_wt8NfTXmIWZYBxbiHXaMH6VZ'\n",
      "DEBUG: Final LLM Response: The current weather in Boston is 72 degrees Celsius.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "OBSERVER METRICS:\n",
      "==================================================\n",
      "Tool Monkey Execution Summary\n",
      "  ==============================\n",
      "  Total Calls: 2\n",
      "  Success Rate: 50.0%\n",
      "  Failures: 1\n",
      "  Total Retries: 0\n",
      "  Avg Latency: 1500.5ms\n"
     ]
    }
   ],
   "source": [
    "def timeout_retry_example():\n",
    "    from langchain_examples.shared.llm import llm\n",
    "    from langchain_examples.shared.tools import base_weather_tool \n",
    "    from langchain_core.tools import tool\n",
    "    from tenacity import retry, stop_after_attempt, wait_exponential_jitter\n",
    "    observer=MonkeyObserver()\n",
    "    scenario=single_timeout(seconds=3.0)\n",
    "\n",
    "    wrapped_weather_tool=with_monkey(scenario, observer)(base_weather_tool)\n",
    "    @retry(\n",
    "        stop=stop_after_attempt(3),\n",
    "        wait=wait_exponential_jitter(initial=0.2, max=2.0),\n",
    "        retry_error_callback=lambda retry_state: \"Weather data unavailable due to timeout\",\n",
    "    )\n",
    "    def weather_tool_with_retry(location:str, units:str=\"celcius\"):\n",
    "        return wrapped_weather_tool(location, units)\n",
    "    \n",
    "\n",
    "    @tool\n",
    "    def get_weather(location: str, units: str = \"celcius\"):\n",
    "        \"\"\"Get the current weather for a given location.\n",
    "            Args:\n",
    "                location (str): The location to get the weather for.\n",
    "                units (str): The units to return the weather in. Either 'celsius' or 'fahrenheit'.\n",
    "            Returns:\n",
    "                str: The current weather in the given location.\"\"\"\n",
    "        return weather_tool_with_retry(location, units)\n",
    "    \n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant with access to a tool to get weather information.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather in Boston?\"}]\n",
    "    llm_with_tool = llm.bind_tools([get_weather])\n",
    "    # invoke the model with the messages\n",
    "    ai_msg = llm_with_tool.invoke(messages)\n",
    "    logger.debug(f\"Full LLM Response: {ai_msg}\")\n",
    "    messages.append(ai_msg)\n",
    "    logger.debug(f\"Have tool calls? {'Yes' if ai_msg.tool_calls else 'No'}\")\n",
    "    try:\n",
    "        for tool_call in ai_msg.tool_calls:\n",
    "            logger.debug(\n",
    "                f\"Invoking tool: {tool_call.get(\"name\")} with args {tool_call.get('args')}\")\n",
    "            tool_result = get_weather.invoke(tool_call)\n",
    "            logger.debug(f\"Tool result: {tool_result}\")\n",
    "            messages.append(tool_result)\n",
    "        final_response = llm_with_tool.invoke(messages)\n",
    "        logger.debug(f\"Final LLM Response: {final_response.text}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"OBSERVER METRICS:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(observer.summary())\n",
    "\n",
    "timeout_retry_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
