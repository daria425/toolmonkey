{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2fc6025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.cwd().parent)) \n",
    "from tool_monkey import MonkeyObserver, with_monkey, retry_exhaustion, logger, setup_default_logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8643b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_default_logging(level=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43f7991",
   "metadata": {},
   "source": [
    "### Example 1: Retry Exhaustion with Tenacity\n",
    "\n",
    "**Use Case:** Weather API consistently times out due to server overload. Retry logic (using tenacity) exhausts all attempts.\n",
    "\n",
    "**What Happens:**\n",
    "1. User asks \"What's the weather in Boston?\"\n",
    "2. LLM calls `get_weather(\"Boston\")`\n",
    "3. **Attempt 1:** Times out after 2 seconds\n",
    "4. **Tenacity retry (attempt 2):** Times out again after 2 seconds\n",
    "5. **Tenacity retry (attempt 3):** Times out again after 2 seconds\n",
    "6. **All retries exhausted** - fallback error message returned\n",
    "7. Agent tells user: \"Weather data unavailable\"\n",
    "\n",
    "**What This Shows:**\n",
    "- Even with retry logic, some failures are persistent (server down, quota exhausted, etc.)\n",
    "- Tenacity's `retry_error_callback` provides graceful fallback message\n",
    "- Proper error handling pattern: retry N times, then give up gracefully\n",
    "- Real pattern: Don't retry forever - set limits\n",
    "\n",
    "**Retry Strategy:**\n",
    "- `stop_after_attempt(3)` - max 3 attempts\n",
    "- `wait_exponential_jitter(initial=0.2, max=2.0)` - exponential backoff with jitter\n",
    "- `retry_error_callback` - returns user-friendly error message when exhausted\n",
    "\n",
    "**Expected Output:**\n",
    "- 3 timeout failures in a row\n",
    "- Observer shows: 3 calls, 0% success rate, 3 failures, 3 retries\n",
    "- Agent receives error message and informs user gracefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547633eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: Full LLM Response: content='' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 134, 'total_tokens': 149, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-CwvgVoDydLStru63AtrYmXnW5TK5e', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='lc_run--019bae98-a99f-79c2-95d0-bbec972320b6-0' tool_calls=[{'name': 'get_weather', 'args': {'location': 'Boston'}, 'id': 'call_sHKxecQ1tbKetxWGuJqeZmOk', 'type': 'tool_call'}] invalid_tool_calls=[] usage_metadata={'input_tokens': 134, 'output_tokens': 15, 'total_tokens': 149, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "DEBUG: Have tool calls? Yes\n",
      "DEBUG: Invoking tool: get_weather with args {'location': 'Boston'}\n",
      "INFO: Simulating timeout for 2.0 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ending call for base_weather_tool after exception\n",
      "Ending call for base_weather_tool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Simulating timeout for 2.0 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ending call for base_weather_tool after exception\n",
      "Ending call for base_weather_tool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Simulating timeout for 2.0 seconds\n",
      "DEBUG: Tool result: content='Weather data unavailable due to timeout' name='get_weather' tool_call_id='call_sHKxecQ1tbKetxWGuJqeZmOk'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ending call for base_weather_tool after exception\n",
      "Ending call for base_weather_tool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: Final LLM Response: I'm sorry, but I'm currently unable to retrieve the weather information for Boston due to a technical issue. Please try again later.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "OBSERVER METRICS:\n",
      "==================================================\n",
      "Tool Monkey Execution Summary\n",
      "  ==============================\n",
      "  Total Calls: 3\n",
      "  Success Rate: 0.0%\n",
      "  Failures: 3\n",
      "  Total Retries: 3\n",
      "  Avg Latency: 2001.7ms\n"
     ]
    }
   ],
   "source": [
    "def timeout_retry_example():\n",
    "    from langchain_examples.shared.llm import llm\n",
    "    from langchain_examples.shared.tools import base_weather_tool \n",
    "    from langchain_core.tools import tool\n",
    "    from tenacity import retry, stop_after_attempt, wait_exponential_jitter\n",
    "    observer=MonkeyObserver()\n",
    "    scenario=retry_exhaustion(num_failures=3, seconds=2)\n",
    "\n",
    "    # first wrap the base tool with the monkey decorator\n",
    "    wrapped_weather_tool=with_monkey(scenario, observer)(base_weather_tool)\n",
    "    # then wrap it with tenacity retry logic\n",
    "    @retry(\n",
    "        stop=stop_after_attempt(3),\n",
    "        wait=wait_exponential_jitter(initial=0.2, max=2.0),\n",
    "        retry_error_callback=lambda retry_state: \"Weather data unavailable due to timeout\",\n",
    "    )\n",
    "    def weather_tool_with_retry(location:str, units:str=\"celcius\"):\n",
    "        return wrapped_weather_tool(location, units)\n",
    "    \n",
    "    # finally define the tool implementation\n",
    "    @tool\n",
    "    def get_weather(location: str, units: str = \"celcius\"):\n",
    "        \"\"\"Get the current weather for a given location.\n",
    "            Args:\n",
    "                location (str): The location to get the weather for.\n",
    "                units (str): The units to return the weather in. Either 'celsius' or 'fahrenheit'.\n",
    "            Returns:\n",
    "                str: The current weather in the given location.\"\"\"\n",
    "        return weather_tool_with_retry(location, units)\n",
    "    \n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant with access to a tool to get weather information.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather in Boston?\"}]\n",
    "    llm_with_tool = llm.bind_tools([get_weather])\n",
    "    # invoke the model with the messages\n",
    "    ai_msg = llm_with_tool.invoke(messages)\n",
    "    logger.debug(f\"Full LLM Response: {ai_msg}\")\n",
    "    messages.append(ai_msg)\n",
    "    logger.debug(f\"Have tool calls? {'Yes' if ai_msg.tool_calls else 'No'}\")\n",
    "    try:\n",
    "        for tool_call in ai_msg.tool_calls:\n",
    "            logger.debug(\n",
    "                f\"Invoking tool: {tool_call.get(\"name\")} with args {tool_call.get('args')}\")\n",
    "            tool_result = get_weather.invoke(tool_call)\n",
    "            logger.debug(f\"Tool result: {tool_result}\")\n",
    "            messages.append(tool_result)\n",
    "        final_response = llm_with_tool.invoke(messages)\n",
    "        logger.debug(f\"Final LLM Response: {final_response.text}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"OBSERVER METRICS:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(observer.summary())\n",
    "\n",
    "timeout_retry_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dd7115",
   "metadata": {},
   "source": [
    "### Example 2: ReAct Agent with retry exhaustion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8ab339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecommerce_react_example():\n",
    "    from langchain_examples.shared.llm import llm\n",
    "    from langchain_examples.shared.tools import base_place_order, base_check_inventory, base_search_products # mock functions \n",
    "    from langchain_core.tools import tool\n",
    "    observer=MonkeyObserver()\n",
    "    scenario=retry_exhaustion(num_failures=3, seconds=3)\n",
    "    wrapped_tool=with_monkey(scenario, observer)(base_check_inventory)\n",
    "    def define_tools():\n",
    "        @tool\n",
    "        def check_inventory(product_id:str, quantity:int):\n",
    "            \"\"\"Check the inventory for a product id and a given quantity. \n",
    "            Assumes quantity is 1 if unspecified by user\n",
    "            Args:\n",
    "                product_id (str): The product id to check inventory for.\n",
    "                quantity (int): The quantity to check inventory for.\n",
    "            \"\"\"\n",
    "            return wrapped_tool(product_id, quantity)\n",
    "        @tool\n",
    "        def search_products(query:str, category: str):\n",
    "            \"\"\"Search for products matching the given query in a category.\n",
    "            Args:\n",
    "                query (str): The search query.\n",
    "                category (str): The product category to search in.\n",
    "            \"\"\"\n",
    "            return base_search_products(query, category) # doesnt fail\n",
    "        @tool\n",
    "        def place_order(product_id:str, quantity:int, customer_email: str):\n",
    "            \"\"\"Place an order for a product id, quantity, and send email to customer.\n",
    "            Args:\n",
    "                product_id (str): The product id to place an order for.\n",
    "                quantity (int): The quantity to order.\n",
    "                customer_email (str): The email address of the customer.\n",
    "            \"\"\"\n",
    "            return base_place_order(product_id, quantity, customer_email)\n",
    "        tools=[check_inventory, search_products, place_order]\n",
    "        return tools\n",
    "    tools=define_tools()\n",
    "    system_msg=\"\"\"\n",
    "  You are a helpful e-commerce assistant. When a user wants to buy something:\n",
    "  1. First, search for products using search_products. The available product categories are electronics, books, and clothing.\n",
    "  2. Then, check inventory using check_inventory to see if it's in stock\n",
    "  3. Finally, place the order using place_order\n",
    "\n",
    "  Always check inventory before placing an order.\n",
    "\"\"\"\n",
    "    user_msg=\"I want to buy a laptop. My email is customer@example.com\"\n",
    "    messages=[\n",
    "        {\"role\":\"system\", \"content\":system_msg},\n",
    "        {\"role\":\"user\", \"content\":user_msg}\n",
    "    ]\n",
    "    llm_with_tools=llm.bind_tools(tools)\n",
    "    max_iterations=10\n",
    "    for i in range(max_iterations):\n",
    "        ai_msg=llm_with_tools.invoke(messages)\n",
    "        messages.append(ai_msg)\n",
    "        if not ai_msg.tool_calls:\n",
    "            print(f\"ReAct Loop finished: {ai_msg.content}\")\n",
    "            break\n",
    "        for tool_call in ai_msg.tool_calls:\n",
    "            tool_name=tool_call[\"name\"]\n",
    "            tool_args=tool_call[\"args\"]\n",
    "            logger.debug(\n",
    "                f\"Invoking tool: {tool_name} with args {tool_args}\")\n",
    "            try:\n",
    "                if tool_name == \"search_products\":\n",
    "                    func=next(t for t in tools if t.name == \"search_products\")\n",
    "                    result = func.invoke(tool_call)\n",
    "                    messages.append(result)\n",
    "                    print(f\"✅ Searched products\")\n",
    "                elif tool_name == \"check_inventory\":\n",
    "                    func=next(t for t in tools if t.name == \"check_inventory\")\n",
    "                    result = func.invoke(tool_call)\n",
    "                    messages.append(result)\n",
    "                    print(f\"✅ Checked inventory\")\n",
    "                elif tool_name == \"place_order\":\n",
    "                    func=next(t for t in tools if t.name == \"place_order\")\n",
    "                    result = func.invoke(tool_call)\n",
    "                    messages.append(result)\n",
    "                    print(f\"✅ Placed order\")\n",
    "            except TimeoutError as e:\n",
    "                print(f\"❌ Timeout: {e}\")\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call[\"id\"],\n",
    "                    \"content\": f\"Error: {e}\"\n",
    "                })\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"OBSERVER METRICS:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(observer.summary())\n",
    "ecommerce_react_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
