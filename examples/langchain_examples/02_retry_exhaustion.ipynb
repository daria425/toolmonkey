{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2fc6025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.cwd().parent)) \n",
    "from tool_monkey import MonkeyObserver, with_monkey, retry_exhaustion, logger, setup_default_logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8643b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_default_logging(level=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43f7991",
   "metadata": {},
   "source": [
    "Example 1: Using `bind_tools` and `tenacity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547633eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: Full LLM Response: content='' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 134, 'total_tokens': 149, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-CwvdAB84oz3LYDmUF7gxqudX0LCTE', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='lc_run--019bae95-7f5e-7c92-997a-3895ca67746e-0' tool_calls=[{'name': 'get_weather', 'args': {'location': 'Boston'}, 'id': 'call_fQty6tmCrwQFSyS5QgaeHlLw', 'type': 'tool_call'}] invalid_tool_calls=[] usage_metadata={'input_tokens': 134, 'output_tokens': 15, 'total_tokens': 149, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "DEBUG: Have tool calls? Yes\n",
      "DEBUG: Invoking tool: get_weather with args {'location': 'Boston'}\n",
      "INFO: Simulating timeout for 2.0 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ending call for base_weather_tool after exception\n",
      "Ending call for base_weather_tool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Simulating timeout for 2.0 seconds\n",
      "DEBUG: Tool result: content='Weather data unavailable due to timeout' name='get_weather' tool_call_id='call_fQty6tmCrwQFSyS5QgaeHlLw'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ending call for base_weather_tool after exception\n",
      "Ending call for base_weather_tool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: Final LLM Response: I'm sorry, but I'm currently unable to retrieve the weather information for Boston due to a technical issue. Please try again later.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "OBSERVER METRICS:\n",
      "==================================================\n",
      "Tool Monkey Execution Summary\n",
      "  ==============================\n",
      "  Total Calls: 2\n",
      "  Success Rate: 0.0%\n",
      "  Failures: 2\n",
      "  Total Retries: 1\n",
      "  Avg Latency: 2001.7ms\n"
     ]
    }
   ],
   "source": [
    "def timeout_retry_example():\n",
    "    from langchain_examples.shared.llm import llm\n",
    "    from langchain_examples.shared.tools import base_weather_tool \n",
    "    from langchain_core.tools import tool\n",
    "    from tenacity import retry, stop_after_attempt, wait_exponential_jitter\n",
    "    observer=MonkeyObserver()\n",
    "    scenario=retry_exhaustion(num_failures=3, seconds=2)\n",
    "\n",
    "    wrapped_weather_tool=with_monkey(scenario, observer)(base_weather_tool)\n",
    "    @retry(\n",
    "        stop=stop_after_attempt(3),\n",
    "        wait=wait_exponential_jitter(initial=0.2, max=2.0),\n",
    "        retry_error_callback=lambda retry_state: \"Weather data unavailable due to timeout\",\n",
    "    )\n",
    "    def weather_tool_with_retry(location:str, units:str=\"celcius\"):\n",
    "        return wrapped_weather_tool(location, units)\n",
    "    \n",
    "\n",
    "    @tool\n",
    "    def get_weather(location: str, units: str = \"celcius\"):\n",
    "        \"\"\"Get the current weather for a given location.\n",
    "            Args:\n",
    "                location (str): The location to get the weather for.\n",
    "                units (str): The units to return the weather in. Either 'celsius' or 'fahrenheit'.\n",
    "            Returns:\n",
    "                str: The current weather in the given location.\"\"\"\n",
    "        return weather_tool_with_retry(location, units)\n",
    "    \n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant with access to a tool to get weather information.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather in Boston?\"}]\n",
    "    llm_with_tool = llm.bind_tools([get_weather])\n",
    "    # invoke the model with the messages\n",
    "    ai_msg = llm_with_tool.invoke(messages)\n",
    "    logger.debug(f\"Full LLM Response: {ai_msg}\")\n",
    "    messages.append(ai_msg)\n",
    "    logger.debug(f\"Have tool calls? {'Yes' if ai_msg.tool_calls else 'No'}\")\n",
    "    try:\n",
    "        for tool_call in ai_msg.tool_calls:\n",
    "            logger.debug(\n",
    "                f\"Invoking tool: {tool_call.get(\"name\")} with args {tool_call.get('args')}\")\n",
    "            tool_result = get_weather.invoke(tool_call)\n",
    "            logger.debug(f\"Tool result: {tool_result}\")\n",
    "            messages.append(tool_result)\n",
    "        final_response = llm_with_tool.invoke(messages)\n",
    "        logger.debug(f\"Final LLM Response: {final_response.text}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"OBSERVER METRICS:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(observer.summary())\n",
    "\n",
    "timeout_retry_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
